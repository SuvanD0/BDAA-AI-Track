{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb93e1c6",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 BDAA Project Series: Intro to AI - LLMs\n",
    "## Live Demo Notebook (matches slide presentation)\n",
    "\n",
    "**This notebook is designed for live coding demos alongside the slide presentation.**  \n",
    "\ud83c\udfaf **Goal:** Hands-on understanding through experimentation\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udccb Agenda (follows slides exactly)\n",
    "1. **Setup** \u2192 Get environment ready\n",
    "2. **NLP & LLMs** \u2192 The big picture (concepts)\n",
    "3. **\ud83d\ude80 Transformers Pipeline Tour** \u2192 Live coding session\n",
    "4. **\ud83c\udf9b\ufe0f Inference Basics** \u2192 Temperature, sampling, beams\n",
    "5. **\u26a0\ufe0f Bias & Limitations** \u2192 Critical awareness demo\n",
    "6. **\ud83c\udfaf Wrap-up** \u2192 Key takeaways\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfac Demo Flow\n",
    "- **Presenter:** Run cells during slides, invite audience input\n",
    "- **Audience:** Suggest text examples, parameters to try\n",
    "- **Format:** Interactive coding, not just showing results\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udd17 Quick Navigation\n",
    "- [\ud83d\udee0\ufe0f Setup](#setup-cell)\n",
    "- [\ud83d\ude80 Pipeline Demos](#pipeline-demos)\n",
    "- [\ud83c\udf9b\ufe0f Inference Tuning](#inference-tuning)  \n",
    "- [\u26a0\ufe0f Bias Examples](#bias-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0138b",
   "metadata": {},
   "source": [
    "## \ud83d\udee0\ufe0f Setup {#setup-cell}\n",
    "\n",
    "**\ud83d\udce2 LIVE DEMO START:** Run this cell first to verify environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c0c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd04 Setting up environment...\n",
      "\u2705 All packages already installed!\n",
      "\u2705 Environment ready!\n",
      "\ud83e\udd16 Transformers version: 4.56.2\n",
      "\ud83c\udfaf Ready for live demos!\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udee0\ufe0f Environment Setup\n",
    "# Run this first! Installs core libraries if needed.\n",
    "\n",
    "print(\"\ud83d\udd04 Setting up environment...\")\n",
    "\n",
    "try:\n",
    "    import transformers, datasets, accelerate, sentencepiece  # noqa: F401\n",
    "    print(\"\u2705 All packages already installed!\")\n",
    "except Exception as e:\n",
    "    print(\"\ud83d\udce6 Installing required packages...\")\n",
    "    %pip -q install -U transformers datasets accelerate sentencepiece\n",
    "    import transformers, datasets, accelerate, sentencepiece  # noqa: F401\n",
    "\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Keep demo clean\n",
    "\n",
    "print(f\"\u2705 Environment ready!\")\n",
    "print(f\"\ud83e\udd16 Transformers version: {transformers.__version__}\")\n",
    "print(\"\ud83c\udfaf Ready for live demos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da6c447",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Pipeline Demos {#pipeline-demos}\n",
    "\n",
    "**\ud83d\udce2 LIVE CODING SECTION:** This matches the \"Transformers in Practice\" slides.\n",
    "\n",
    "**\ud83c\udfac Demo Format:**\n",
    "- I'll run each cell live\n",
    "- **Audience:** Suggest your own text examples!  \n",
    "- **Goal:** See how easy transformers are to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221e644",
   "metadata": {},
   "source": [
    "# Hugging Face Course \u2014 Chapters 1\u20132 (Combined)\n",
    "\n",
    "**Source notebooks merged:**\n",
    "- `Transformers,_what_can_they_do_.ipynb`\n",
    "- `Bias_and_limitations.ipynb`\n",
    "\n",
    "> All code cells remain unchanged from the originals. Cells are grouped by source notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e9503",
   "metadata": {},
   "source": [
    "# Part A \u2014 Transformers: what can they do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60213bdd",
   "metadata": {
    "id": "udN1wRRCdlTY"
   },
   "source": [
    "# Transformers, what can they do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b101a9",
   "metadata": {
    "id": "PbTrkV7adlTZ"
   },
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1103ba0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFm5LcKNdlTZ",
    "outputId": "77cb1b99-962d-4b14-e24f-00cd55e3713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[sentencepiece]\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d921e9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349,
     "referenced_widgets": [
      "03c7b492795a424c91a27504e0f0e91e",
      "285cc7b05a5446c78d5646981f06f9cd",
      "821a825ef6da452fabd74914c0efa548",
      "3cafbf5ddf924998a1416f918dafae4f",
      "70f70097302142a3be70b9303528e0f2",
      "306fa2d05b7f4c4fa243c0053222fc95",
      "0364d521f4f14ed7b204f80bfbb4ce85",
      "ef4f6faadb4a446bb244814395e3c84a",
      "bfc35690fe50477c9b933dd419597b0e",
      "3b7fc5122a314e5680160fdfd0e9340d",
      "ee888ccf908f4d4a9c1da3bf8441e05c",
      "d32a48b84b764028b8404ea115850cff",
      "c8b086fd577741b79cfd322342780ce6",
      "62096b0226cf44bfb0737bc08350aa2c",
      "ddd1a6745aa9483ab26b7b84315224eb",
      "b4fcd984f0684de7b52418c91e01938e",
      "bc4a9614244c4d618962eb6a87eff714",
      "6f31b46a1f7348fd9029eb7e85137fab",
      "f16d1948e89045c89a1c36a37172fb5a",
      "e19b04d3ce1942dea483175cd43ed1f2",
      "4ee59e1743e949e490e45a6f9ffc5a00",
      "a0e54ccaf9e14e97b1efb0dad280ad6d",
      "39c1e8a69d3a413f8516cbc2c45192ea",
      "3a436e97db214753895cbf03faf2f559",
      "b774e146d52343f5a4e79bd9cbf90476",
      "ab7d8ef17b1f401aac0a214f854ecf5d",
      "02cc35e4b6a340c39e2db1fc58534322",
      "5c8e7e4a4b894cf0b4826c612e2bdbb7",
      "2de3e655874c4a8db45de94f44871843",
      "ee89e55805b14d8c98b3e9ebaf5fd576",
      "b2d1025bb8b94e909a93222b524ef6af",
      "aebc885e6c934875aa15b1da605e2863",
      "d4fb0723f7ca479b83c09a520c7b729a",
      "31667071a015412ea8f7bb1bb8f930c6",
      "ecf2b8e15ada466fb3c8edc05a509632",
      "bbd897b0129a4740840ee80c1ca42ae7",
      "4118a5571cd842f3a19c0924211fecc5",
      "b8b02177cb83436c8110ed3f222e1cd8",
      "bf5079c9ea3349469bb5a6d266829269",
      "9c8d66aa9d084eb08ee26a3be3e5c8d9",
      "f5c868ef68b241ce8bff52a5fc43e4cb",
      "56c26401022a46c3a813b26c92363e4d",
      "35484e2150124b87a7fb8a6ce8ee120c",
      "8b8fe5f92ae140e5ae3aa3575825f99c"
     ]
    },
    "id": "-JI9ZqSMdlTZ",
    "outputId": "1426a00a-3af1-4ca4-9637-ac0e423deaff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Demo 1: Sentiment Analysis Pipeline\n",
      "\ud83d\udca1 This automatically downloads and uses a pre-trained model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Input: 'I've been waiting for a HuggingFace course my whole life.'\n",
      "\ud83c\udfaf Result: [{'label': 'POSITIVE', 'score': 0.9598049521446228}]\n",
      "\n",
      "\ud83d\udcbb YOUR TURN: What text should we analyze next?\n",
      "   (I'll take suggestions from the audience!)\n"
     ]
    }
   ],
   "source": [
    "# \ud83d\udcbb LIVE DEMO: Sentiment Analysis (Quick Win!)\n",
    "# \ud83c\udfaf Slide match: \"Sentiment Analysis (quick win)\"\n",
    "\n",
    "print(\"\ud83d\ude80 Demo 1: Sentiment Analysis Pipeline\")\n",
    "print(\"\ud83d\udca1 This automatically downloads and uses a pre-trained model\")\n",
    "print()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create the pipeline (first run downloads model)\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Try with a positive example\n",
    "result = classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "print(\"\ud83d\udcdd Input: 'I've been waiting for a HuggingFace course my whole life.'\")\n",
    "print(f\"\ud83c\udfaf Result: {result}\")\n",
    "print()\n",
    "\n",
    "# \ud83c\udfac AUDIENCE INTERACTION PROMPT\n",
    "print(\"\ud83d\udcbb YOUR TURN: What text should we analyze next?\")\n",
    "print(\"   (I'll take suggestions from the audience!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a849b4",
   "metadata": {
    "id": "uZdPB1QDdlTa",
    "outputId": "d0ad46e0-bf61-42ad-a34a-488b6095068b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Batch Results:\n",
      "\ud83d\ude0a 'I've been waiting for a HuggingFace course my whol...' \u2192 POSITIVE (0.960)\n",
      "\ud83d\ude1e 'I hate this so much!...' \u2192 NEGATIVE (0.997)\n",
      "\n",
      "\ud83d\udca1 Key insight: Works great for English text!\n",
      "\ud83e\udd14 Question for audience: What languages might this struggle with?\n"
     ]
    }
   ],
   "source": [
    "# \ud83c\udfaf Multiple examples at once\n",
    "# \ud83c\udfac LIVE: Let's try both positive and negative examples\n",
    "\n",
    "# Batch processing - more efficient!\n",
    "examples = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",  # Positive\n",
    "    \"I hate this so much!\"  # Negative\n",
    "]\n",
    "\n",
    "results = classifier(examples)\n",
    "\n",
    "print(\"\ud83d\udcca Batch Results:\")\n",
    "for text, result in zip(examples, results):\n",
    "    emoji = \"\ud83d\ude0a\" if result['label'] == 'POSITIVE' else \"\ud83d\ude1e\" \n",
    "    print(f\"{emoji} '{text[:50]}...' \u2192 {result['label']} ({result['score']:.3f})\")\n",
    "\n",
    "print()\n",
    "print(\"\ud83d\udca1 Key insight: Works great for English text!\")\n",
    "print(\"\ud83e\udd14 Question for audience: What languages might this struggle with?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5f3a92",
   "metadata": {
    "id": "yUghMD9wdlTa",
    "outputId": "11cc6e9d-efd5-4093-8344-924d54c2e886"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Demo 2: Zero-shot Classification\n",
      "\ud83c\udfaf Use your own labels - no training needed!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Text: 'This is a course about the Transformers library'\n",
      "\ud83c\udff7\ufe0f Candidate labels: education, politics, business\n",
      "\ud83d\udcca Results:\n",
      "  education  0.845 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n",
      "  business   0.112 \u2588\u2588\n",
      "  politics   0.043 \n",
      "\n",
      "\ud83d\udcbb AUDIENCE CHALLENGE:\n",
      "   1. Give me any text\n",
      "   2. Give me 3-4 categories\n",
      "   3. Let's see what happens!\n"
     ]
    }
   ],
   "source": [
    "# \ud83c\udfaf LIVE DEMO: Zero-shot Classification\n",
    "# \ud83c\udfaf Slide match: \"Zero-shot Classification\"\n",
    "\n",
    "print(\"\ud83d\ude80 Demo 2: Zero-shot Classification\")\n",
    "print(\"\ud83c\udfaf Use your own labels - no training needed!\")\n",
    "print()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Example from slides\n",
    "result = classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")\n",
    "\n",
    "print(\"\ud83d\udcdd Text: 'This is a course about the Transformers library'\")\n",
    "print(\"\ud83c\udff7\ufe0f Candidate labels: education, politics, business\")\n",
    "print(\"\ud83d\udcca Results:\")\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    bar = \"\u2588\" * int(score * 20)  # Visual bar\n",
    "    print(f\"  {label:10} {score:.3f} {bar}\")\n",
    "\n",
    "print()\n",
    "print(\"\ud83d\udcbb AUDIENCE CHALLENGE:\")\n",
    "print(\"   1. Give me any text\")  \n",
    "print(\"   2. Give me 3-4 categories\")\n",
    "print(\"   3. Let's see what happens!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3623a01",
   "metadata": {
    "id": "1dOb5FCRdlTa",
    "outputId": "3dbad1ac-25cc-4045-bd26-7a95fe68611e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to use a large, high-speed computer to create simple and easy to use user interfaces.\\n\\nIn this course, we will show you how to create basic user interfaces using PowerShell. We will show you how to create a user interface using a PowerShell script.\\n\\nIn this course, we will show you how to create an interface using PowerShell. We will show you how to create a user interface using a PowerShell script.\\n\\nIn this course, we will show you how to create an interface using PowerShell. We will show you how to create an interface using a PowerShell script.\\n\\nIn this course, we will show you how to create an interface using PowerShell. We will show you how to create an interface using a PowerShell script.\\n\\nIn this course, we will show you how to create an interface using PowerShell. We will show you how to create an interface using a PowerShell script.\\n\\nIn this course, we will show you how to create an interface using PowerShell. We will show you how to create an interface using a PowerShell script.\\n\\nIn this course, we will show you how to create an interface using PowerShell. We will show you how to create an interface using a PowerShell script.\\n\\nIn this course, we will show you how'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f912a846",
   "metadata": {
    "id": "Ata_h6xtdlTa",
    "outputId": "76a82fb7-d840-4ea1-984e-81bf6b2f478b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to set up the OpenOffice 365 project.\\n\\n\\n\\n\\n\\nIf you prefer to learn more about OpenOffice 365, you can follow the full course here.\\n\\nIf you are interested in learning more about OpenOffice 365, you can follow the full course here.\\nWith the latest release, you can learn about the new features of OpenOffice 365, and how to implement them in your projects.\\nThis course will help you learn about the new features of OpenOffice 365, and how to implement them in your projects.'},\n",
       " {'generated_text': 'In this course, we will teach you how to create a virtual reality headset in real-time.\\n\\n\\n\\nIf you like this course, please go to the courses listed below or subscribe to our newsletter for more courses.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc08b78",
   "metadata": {
    "id": "GlbGcIE5dlTa",
    "outputId": "96e8a2f6-812a-424f-cac3-3ab20f1e31fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19620011746883392,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052743315696716,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5b6815",
   "metadata": {
    "id": "dwdg_2BUdlTb",
    "outputId": "18202c90-ca97-4479-a1e3-cc69fbdfafce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9981694),\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9796019),\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9932106),\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c272252f",
   "metadata": {
    "id": "PkRWsFkKdlTb",
    "outputId": "ec4732b8-1b69-4bf3-a27d-bbcc0f18b4af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949756145477295, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26470583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319,
     "referenced_widgets": [
      "2a920759e1854b11bcd1bd5037d1bc91",
      "023e557a9b5f4dc7b1f18ae639dced59",
      "5ae545fa4cf147eaad9fb76b83192354",
      "1f49711eaa9a4efa8a96a32cd0d3c36c",
      "c3c98e81384b44c7b26f7aaae5d59ba4",
      "0d57e65f0d3146c9bbefd4d6129beb5a",
      "0c17ac361f7842c09c6053f3c8f073b2",
      "d91ba2a35d364504a5c202e23a65ea0d",
      "2077139201464b3cbe91b68f971b94ed",
      "96f630eeb6844d8facb5ece08fd1fdca",
      "6e709793f0bd44998e4541f088b92b18",
      "92148b7c0ffc4740972ea990155bfad4",
      "fa014b14d0a84759a8d10b5fe8a1dcdd",
      "fd523611a58c40eebdb5e61bb3fb97ba",
      "adfc6bd994bc43aaa038065cdfb481f6",
      "2f773dbcfdb04c538bd99a8e75a9ea1f",
      "a4bccf60199b4e40998615b2d07b63bb",
      "ef16953295394d448be8c7b9534dfc0c",
      "b5ae2cf565f544f88126cf22fdf88a71",
      "ae55f958d1854f74a48f95079a7b01c0",
      "7e34967c0c9549f9b58ad3600b6ff2bc",
      "9cd1189916b644c3ba88beed1182b37a",
      "80eee477b85c4c47b8a068f35ab00717",
      "d4365b75f6e3426ebb176cdf751bb176",
      "94b0ab259bbf401c874ec81e74ac2361",
      "ee93e83015704da7bfb6cc8a9b882c41",
      "eea3f54e9ce44b5a8856bd1bdcf54617",
      "141aa7b2e73344c2afe296514c2a5569",
      "58524d4c88fa402fbeeb375354e186ed",
      "e236bf9187b041d78cd6efbd15239eac",
      "3ced70d378664dd39253988c6436244b",
      "1d23ff633ab94f178a9363061b039b9d",
      "39b8333dee8c489ba66e5caf1eed3fba",
      "8e03b5ab92904b62bde764cedee376aa",
      "c0185bdca3ca42d0a2987f3d39ea319f",
      "5d2c70b510604c54b20abc81f7081024",
      "6376e3f5078c49dbb7f178e3257b67b4",
      "3997e7bb8c5d4934bb27801697b7c2af",
      "53686c395db04a8d809dab4df1575580",
      "1ac049a7aa9b4d3c8d473ae9defc9991",
      "c751747c85c64b0d9ac227ed13f2d53e",
      "391dfa127f084f84a369d84256a5d80b",
      "7e720c3eb4014a508553b92c87f54dc9",
      "07b503e42787494182dbe5af9c89b8ec",
      "57d3621a54fb4fbaa5000b8ad2df23d1",
      "de6bdd0d42fe4408b7a412af82e0ce3e",
      "bebdcc33fb054a68be7c3a3f103d6b28",
      "469c13eb8c0549f7819a54bf05263da1",
      "b6fa9118271d42e386493bb59d4899ee",
      "8cfc151100bb4e8a87cd07bf9bd36b31",
      "26f3059404474405b9bef1a143970669",
      "164cb6db5c7b4cb0829219698954f703",
      "e7276652db1a4b32be0da078eda71160",
      "f013ee4bf98943b282d33cdbc36c09fe",
      "494e436575704622a3f1e6f8dbc8fa3b",
      "2e8586b06434430eb5c075c40fb9433f",
      "9618f4dcb05c44dc81d236528956b128",
      "a3f02c1d5ae04d9e999c9811832084a6",
      "36a28b111db547b6afa6cf50acc16004",
      "0ba80b6e37b8421b9df54ed744f6785a",
      "7e671d3bcf7a4f279831f4c5d3e36b0f",
      "43b29fc066134383ad78df5a24702bc7",
      "e18dd8c5022e46fe8bcccb69d729205f",
      "0d2d15c5b8cc448383fe50eb39114c0a",
      "46aeb72702584f8cbbc0a27e060bd228",
      "f3019f17f4014ca48b33a54d5d9eb4e6"
     ]
    },
    "id": "p5yY5DMgdlTc",
    "outputId": "098f7f46-8087-4b9f-90f2-c971eda57175"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The number of engineering graduates in the United States has declined in recent years . China and India graduate six and eight times as many traditional engineers as the U.S. does . Rapidly developing economies such as China continue to encourage and advance the teaching of engineering . There are declining offerings in engineering subjects dealing with infrastructure, infrastructure, the environment, and related issues .'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of\n",
    "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
    "    the premier American universities engineering curricula now concentrate on\n",
    "    and encourage largely the study of engineering science. As a result, there\n",
    "    are declining offerings in engineering subjects dealing with infrastructure,\n",
    "    the environment, and related issues, and greater concentration on high\n",
    "    technology subjects, largely supporting increasingly complex scientific\n",
    "    developments. While the latter is important, it should not be at the expense\n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other\n",
    "    industrial countries in Europe and Asia, continue to encourage and advance\n",
    "    the teaching of engineering. Both China and India, respectively, graduate\n",
    "    six and eight times as many traditional engineers as does the United States.\n",
    "    Other industrial countries at minimum maintain their output, while America\n",
    "    suffers an increasingly serious decline in the number of engineering graduates\n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d59239",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346,
     "referenced_widgets": [
      "430b698e641d429d8cf0048fd5e9fdf0",
      "e8f836f724d34469b83c513cdb932fe2",
      "cc2cfd5878074957a4cb7450149f2d38",
      "52298ef542f04c28910a9d6ed2f73dee",
      "fb393c3f5b3d4314bf31246da138e254",
      "60930e3c4bce47a6ad126cb6d6989a00",
      "437621a1b30147d8ad3a13400f6207b9",
      "5882b3b3ff494fe4a8085f3122c7c154",
      "5e8618ff98814aa8a93846530ae1ac00",
      "9cd3b04ac51f4c059edb708d9d46017b",
      "8a703e3c12d04a3aa232b41c861fadf8",
      "711239af4d62457184d101dee3e2c9c4",
      "87183f53d56549309fc3071e44eebd8f",
      "6b0a386a64684a898813b9615597bc7d",
      "9e0eab21bae842dc92e0d019489bdbe7",
      "f7e5d7a79885421eb680f9a725997646",
      "9cafb5f93ca8431c90783c54d5b91c51",
      "a74cac15b0044f24959b415a3fbbaa12",
      "2f078ec662e74acea5b0968cbd821334",
      "b0a9a4eda2e74caa880eac1a4d9a424a",
      "1d9081ebbdd54174b0136f9262ceda63",
      "f521a13b224142bb9c1df1bbabc0d022",
      "d3a982ba6e6e438ab0b59184bb89308c",
      "805057909ad349dbba8a9a066e4225d6",
      "5e81fafa2a794c1dafc99b39148c7034",
      "6c11159cec5642258d9ffb3f7a444f16",
      "9b9c896d9a8848178fdf7d32d30e0bb8",
      "19bf8144bcb0456f9c8f8fdd83122faa",
      "8926f27d52384797b0bba70fdedeb71c",
      "a7cc1c69ec314c16a87d2668141fe367",
      "c70901d953f8482a861ec9166467b243",
      "07b87308839444c9ba22029fa0a3aa3e",
      "19d6779df0c8404cab5af18534ea69d7",
      "83b242c62a0242289d522844bdec474e",
      "8f5143aa98d040faa57ea435d7ad688f",
      "8c96e598977c464da25d867ad1ad22cf",
      "b4f94df7e10349b7b9e6a10746ada066",
      "716fb84fc21b4949a9f217f82566dd33",
      "c2d0d463015b494191fd7d702a45b9b9",
      "07ce2e02245a4c0d9f5188f85736be3f",
      "a5e309f3008c4f9cbdc15c3424cf6029",
      "d56b9ccabb0246a5a4813eeb89225e87",
      "3f28a8f0398046e393baf7cce0953be8",
      "e6a771e82de443b685fdf30eab5eea51",
      "802a43efe41e4c96b03279b4ac12df55",
      "14d2fa3caf9e4ab09a07c38c3ed46724",
      "a1bf646b98a645c1b828a765eb949bc5",
      "2ae63acebc0f4d5698f2ee0e3bf84a7c",
      "040d20e8ac894f5c930373adca513a58",
      "2ee9ceebf3094964b08c43b2c6caaae7",
      "26ed144d0b694f3eb9f983bcbc48bbd0",
      "a66f2e52991d4849930855b8111fdfe0",
      "4edb9f54c4864227ba5c825f9ee08174",
      "efc8bfb3540047e39b3436456f6c1ff5",
      "ece6e045a6594359959dc226cff8f8b4",
      "f8bbdfe2aff1475688f6e8a6a694f6ee",
      "e0222951c7604e9bbe42c263916440d0",
      "e0af1a2b88794f8db4e00d3ddc72251b",
      "b978079f297d43afb0b975b77a092b01",
      "7e43226f0f1f4c628e7c23ef04f13113",
      "e0a29ed160cd4f10a57e90842c9179a0",
      "a1c9db93f01e4bdba3ff272ae72de93c",
      "7a4e8394555b454e96df2464365b6517",
      "8714ac5997524b64b1fd80ed1d3a7ead",
      "796a20e8efea4c91a821cbc6b41f8f9f",
      "accbc1fb04384f24ac5f33ab0f2670fb",
      "d15b17d332a942fdb379ee7271e5b829",
      "fd561762de844ee49c811b6c94b20597",
      "54da2cc5e64842d093bf2b646969f91a",
      "2af540dc9bb444329818382533b74460",
      "0ac0543b097b438696dffa75a6611970",
      "94a2dafcb3434c6aa1900c8ce515283c",
      "8cfac84df04e4cbf8d64c14b3681c6a9",
      "3b4cd7da58ba4edb92c062ccc895c434",
      "cb4b4d95b3a14f5085af11b395740e96",
      "b683726119ef43258c7f6b3dd8bdc530",
      "abf5e5f7c12e4d6ebe0c1a54a347b6f5",
      "ea21132e21f044359c989c0fb81d9bcb",
      "f8a4234496334dc8a2a7cb7afea19ae9",
      "c2be31e3087e4d86b2fe6613dbf44e21",
      "aafd75fd205c4c4baedd8f1196540878",
      "f71c40f582114d079e30e74cdf337f9b",
      "237cdc47803c4b22922abcdc115970a5",
      "b88b3e3600364c75a947a669823f0c58",
      "e59d6420526d4852a17423e385c52072",
      "4cb1b36377f548aaa15ad5dad469915c",
      "7d95d9c0b0d449be8d6d372a6771d662",
      "3693bca3c4f34dc3868206b88f4c1092"
     ]
    },
    "id": "XgnipJrrdlTc",
    "outputId": "1e399416-7e23-426e-a9ff-51075cfd9519"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287b6b2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17963beb",
   "metadata": {},
   "source": [
    "## \ud83c\udf9b\ufe0f Inference Tuning {#inference-tuning}\n",
    "\n",
    "**\ud83d\udce2 LIVE DEMO:** This matches the \"Inference Basics\" slides\n",
    "\n",
    "**\ud83c\udfaf Learning Goals:**\n",
    "- See how temperature affects creativity\n",
    "- Compare top-k vs top-p sampling  \n",
    "- Understand beam search vs sampling\n",
    "- Feel the difference in generation quality\n",
    "\n",
    "**\ud83c\udfac Demo Strategy:** Run same prompt with different settings, compare outputs live!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff77e3",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- *Prefill* = initial pass over the prompt (impacts **TTFT**: time-to-first-token).\n",
    "- *Decode* = token-by-token generation (impacts **TPOT**: time-per-output-token).\n",
    "- Sampling: `temperature`, `top_k`, `top_p` (nucleus), plus repetition penalties.\n",
    "- Beam search explores multiple candidates for more coherent text.\n",
    "- KV cache reuses attention keys/values to speed up decoding (model/pipeline may manage this internally).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9986fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Demo: Temperature & Sampling Effects\n",
      "\ud83c\udfaf Same prompt, different parameters = different personalities!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Prompt: 'Write a single friendly sentence about learning Transformers:'\n",
      "============================================================\n",
      "\ud83e\udd76 LOW TEMPERATURE (0.2) - Conservative & Predictable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Result: The Last Knight.\n",
      "\n",
      "I\u2019m not sure if I\u2019ve ever written a sentence like that before. I\u2019m not sure if I\n",
      "\n",
      "\ud83d\udd25 HIGH TEMPERATURE (1.1) - Creative & Wild\n",
      "   Result: Optimus Prime's \"Eh, he's a robot, so that means it's probably going to be a shitty Transformers cartoon\".\n",
      "\n",
      "\ud83d\udca1 Key insight: Temperature controls creativity vs consistency!\n",
      "\ud83e\udd14 Audience question: When would you want high vs low temperature?\n"
     ]
    }
   ],
   "source": [
    "# \ud83c\udf9b\ufe0f LIVE DEMO: Sampling Controls\n",
    "# \ud83c\udfaf Slide match: \"Sampling Controls\"\n",
    "\n",
    "print(\"\ud83d\ude80 Demo: Temperature & Sampling Effects\")\n",
    "print(\"\ud83c\udfaf Same prompt, different parameters = different personalities!\")\n",
    "print()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use a small, fast model for demos\n",
    "gen = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
    "\n",
    "# Fixed prompt for comparison\n",
    "prompt = \"Write a single friendly sentence about learning Transformers:\"\n",
    "\n",
    "print(f\"\ud83d\udcdd Prompt: '{prompt}'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# \ud83e\udd76 Conservative/Deterministic (low temperature)\n",
    "print(\"\ud83e\udd76 LOW TEMPERATURE (0.2) - Conservative & Predictable\")\n",
    "out_calm = gen(prompt, max_new_tokens=30, temperature=0.2, top_p=0.95, do_sample=True)\n",
    "print(f\"   Result: {out_calm[0]['generated_text'].split(prompt)[1].strip()}\")\n",
    "print()\n",
    "\n",
    "# \ud83d\udd25 Creative (higher temperature) \n",
    "print(\"\ud83d\udd25 HIGH TEMPERATURE (1.1) - Creative & Wild\")\n",
    "out_creative = gen(prompt, max_new_tokens=30, temperature=1.1, top_p=0.9, do_sample=True)\n",
    "print(f\"   Result: {out_creative[0]['generated_text'].split(prompt)[1].strip()}\")\n",
    "print()\n",
    "\n",
    "print(\"\ud83d\udca1 Key insight: Temperature controls creativity vs consistency!\")\n",
    "print(\"\ud83e\udd14 Audience question: When would you want high vs low temperature?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "632d3e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Demo: Beam Search - More Coherent, Higher Cost\n",
      "\ud83c\udfaf Explores multiple possibilities, picks the best overall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcdd Prompt: 'Summarize the benefits of transfer learning in one sentence:'\n",
      "============================================================\n",
      "\ud83c\udfaf BEAM SEARCH (num_beams=4) - Coherent & Structured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Result: Transfer learning is a powerful technique that allows us to leverage the knowledge gained from one task to improve performance on another task. It involves using pre-trained models to\n",
      "\n",
      "\ud83c\udfb2 SAMPLING (temperature=0.7) - More Varied\n",
      "   Result: Transfer learning is a powerful technique that allows us to leverage the knowledge gained from one task to solve a similar task. These benefits can be summarized as follows:\n",
      "\n",
      "\ud83d\udca1 Trade-off: Beam search = coherent but slower, Sampling = faster but variable\n",
      "\ud83e\udd14 Which would you use for a chatbot vs creative writing?\n"
     ]
    }
   ],
   "source": [
    "# \ud83c\udfaf LIVE DEMO: Beam Search vs Sampling\n",
    "# \ud83c\udfaf Slide match: \"Beam Search\"\n",
    "\n",
    "print(\"\ud83d\ude80 Demo: Beam Search - More Coherent, Higher Cost\")\n",
    "print(\"\ud83c\udfaf Explores multiple possibilities, picks the best overall\")\n",
    "print()\n",
    "\n",
    "# Same model, beam search settings\n",
    "gen_beam = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
    "prompt = \"Summarize the benefits of transfer learning in one sentence:\"\n",
    "\n",
    "print(f\"\ud83d\udcdd Prompt: '{prompt}'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# \ud83c\udfaf Beam search (deterministic, more coherent)\n",
    "print(\"\ud83c\udfaf BEAM SEARCH (num_beams=4) - Coherent & Structured\")\n",
    "out_beam = gen_beam(prompt, max_new_tokens=35, num_beams=4, do_sample=False)\n",
    "print(f\"   Result: {out_beam[0]['generated_text'].split(prompt)[1].strip()}\")\n",
    "print()\n",
    "\n",
    "# \ud83c\udfb2 Compare with sampling\n",
    "print(\"\ud83c\udfb2 SAMPLING (temperature=0.7) - More Varied\")  \n",
    "out_sample = gen_beam(prompt, max_new_tokens=35, temperature=0.7, do_sample=True)\n",
    "print(f\"   Result: {out_sample[0]['generated_text'].split(prompt)[1].strip()}\")\n",
    "print()\n",
    "\n",
    "print(\"\ud83d\udca1 Trade-off: Beam search = coherent but slower, Sampling = faster but variable\")\n",
    "print(\"\ud83e\udd14 Which would you use for a chatbot vs creative writing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733dbfd",
   "metadata": {},
   "source": [
    "**KV Cache note**  \n",
    "Most modern generation backends (including `transformers` with compatible models) maintain a key\u2011value cache under the hood during decoding to avoid recomputing attention for previous tokens. You don't usually need to toggle anything explicitly in a basic `pipeline`, but when building custom generation loops, look for `use_cache=True` and check memory usage when pushing long contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be5bf4",
   "metadata": {},
   "source": [
    "## \u26a0\ufe0f Bias Examples {#bias-examples}\n",
    "\n",
    "**\ud83d\udce2 CRITICAL DEMO:** This matches the \"Bias and Limitations\" slides\n",
    "\n",
    "**\u26a0\ufe0f Important Context:**\n",
    "- We're going to see problematic bias in action\n",
    "- This is **educational** - to raise awareness  \n",
    "- **Goal:** Understand why evaluation and mitigation matter\n",
    "- **Real-world impact:** These biases affect actual applications\n",
    "\n",
    "**\ud83c\udfaf Learning Objective:** Recognize that even powerful models carry societal biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44715e8d",
   "metadata": {
    "id": "GQ6F6g8U3NNP"
   },
   "source": [
    "# Bias and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f657c",
   "metadata": {
    "id": "9yjOT8uT3NNQ"
   },
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad77204",
   "metadata": {
    "id": "BiTTxFEy3NNQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[sentencepiece]\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30c1bfe1",
   "metadata": {
    "id": "TYftr0-g3NNR",
    "outputId": "d27cff29-8f03-4df8-a39e-29f0150c11f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f BIAS AWARENESS DEMO\n",
      "\ud83c\udfaf We'll see problematic stereotypes in a pre-trained model\n",
      "\ud83d\udcda This is EDUCATIONAL - to understand why bias matters\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d Testing: Occupation predictions by gender\n",
      "==================================================\n",
      "\ud83d\udc68 Input: 'This man works as a [MASK].'\n",
      "   Predictions: ['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "\n",
      "\ud83d\udc69 Input: 'This woman works as a [MASK].'\n",
      "   Predictions: ['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n",
      "\n",
      "\u26a0\ufe0f NOTICE THE BIAS:\n",
      "   Men \u2192 carpenter, lawyer, farmer\n",
      "   Women \u2192 nurse, maid, teacher\n",
      "\n",
      "\ud83d\udca1 This reflects biases in training data (text from the internet)\n",
      "\ud83c\udfaf Why this matters: Real applications can perpetuate stereotypes\n",
      "\u2705 Solutions: Bias evaluation, filtering, diverse teams, human oversight\n"
     ]
    }
   ],
   "source": [
    "# \u26a0\ufe0f CRITICAL DEMO: Gender Bias in Fill-Mask\n",
    "# \ud83c\udfaf Slide match: \"Bias Example (Fill-Mask)\"\n",
    "\n",
    "print(\"\u26a0\ufe0f BIAS AWARENESS DEMO\")\n",
    "print(\"\ud83c\udfaf We'll see problematic stereotypes in a pre-trained model\")\n",
    "print(\"\ud83d\udcda This is EDUCATIONAL - to understand why bias matters\")\n",
    "print()\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Use BERT for fill-mask\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Test with gendered sentences\n",
    "print(\"\ud83d\udd0d Testing: Occupation predictions by gender\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Male version\n",
    "print(\"\ud83d\udc68 Input: 'This man works as a [MASK].'\")\n",
    "result_man = unmasker(\"This man works as a [MASK].\")\n",
    "man_jobs = [r[\"token_str\"] for r in result_man]\n",
    "print(f\"   Predictions: {man_jobs}\")\n",
    "print()\n",
    "\n",
    "# Female version  \n",
    "print(\"\ud83d\udc69 Input: 'This woman works as a [MASK].'\")\n",
    "result_woman = unmasker(\"This woman works as a [MASK].\")\n",
    "woman_jobs = [r[\"token_str\"] for r in result_woman]\n",
    "print(f\"   Predictions: {woman_jobs}\")\n",
    "print()\n",
    "\n",
    "print(\"\u26a0\ufe0f NOTICE THE BIAS:\")\n",
    "print(f\"   Men \u2192 {', '.join(man_jobs[:3])}\")\n",
    "print(f\"   Women \u2192 {', '.join(woman_jobs[:3])}\")\n",
    "print()\n",
    "print(\"\ud83d\udca1 This reflects biases in training data (text from the internet)\")\n",
    "print(\"\ud83c\udfaf Why this matters: Real applications can perpetuate stereotypes\")\n",
    "print(\"\u2705 Solutions: Bias evaluation, filtering, diverse teams, human oversight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ydkobsjqlk",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Wrap-up & Next Steps\n",
    "\n",
    "**\ud83c\udf89 What we accomplished in this live demo:**\n",
    "\n",
    "\u2705 **Environment Setup** \u2192 Got transformers working  \n",
    "\u2705 **Pipeline Tour** \u2192 Tried 6+ different tasks with zero training  \n",
    "\u2705 **Inference Tuning** \u2192 Saw how parameters change behavior  \n",
    "\u2705 **Bias Awareness** \u2192 Recognized real-world challenges  \n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\ude80 Key Takeaways\n",
    "1. **`pipeline()` = your best friend** \u2192 Quick path to working demos\n",
    "2. **Choose architecture by task** \u2192 Encoder/Decoder/Seq2Seq\n",
    "3. **Tune inference parameters** \u2192 Temperature, sampling, beams\n",
    "4. **Always evaluate for bias** \u2192 Don't deploy without checking\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfaf Interactive Q&A\n",
    "**\ud83d\udcbb Let's try YOUR examples!**\n",
    "- Bring any text you want to classify, generate, or analyze\n",
    "- Suggest parameter combinations to experiment with\n",
    "- Ask about specific use cases for your projects\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcda Continue Learning\n",
    "- **Hugging Face Course:** Full chapters with more advanced topics\n",
    "- **Model Hub:** 100,000+ models to explore\n",
    "- **Datasets:** Pre-built datasets for training/evaluation\n",
    "- **Community:** Forums, Discord, tutorials\n",
    "\n",
    "**\ud83c\udfaf Remember:** Start simple with `pipeline()`, then dive deeper!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Transformers, what can they do?",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}